---
title: "「試して理解 Linux のしくみ」を読んだので振り返る"
emoji: "⚙️"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["Linux", "OS"]
published: false
published_at: "2024-09-15 19:00"
---

「試して理解 Linux のしくみ 増補改訂版（2022/10/29、技術評論社）」を読み終わったので振り返りながら各章について印象に残ったことを書いていきます。

## 注意

- 本記事はタイトル通り Linux の概念を解説する記事ではなく Linux の入門書を読んだ感想なので、そこを期待して読み始めた方はそっとブラウザバックしてください！
- 低レイヤに入門し始めたばかりなので、間違えたことを言っていたらやさしく教えて下さい

## どんな書籍か

### 書籍概要

実際に手を動かしながら OS（Linux）の概念を学んでいくというコンセプトの書籍です。

「OS の特定の概念を図解で説明したあと、その概念を実験で確かめる」という構成で書かれています。実験では、シェルの対話環境でコマンドを実行したり、シェルスクリプト / Go / Python で書かれた計測、可視化用のプログラムを実行したりします。

https://gihyo.jp/book/2022/978-4-297-13148-7

以下、公式サイトの書籍紹介を引用します。

> IT システムやソフトウェアの基盤 OS として幅広く使われている Linux。エンジニアとして Linux に関する知識はいまや必須とも言えますが，あなたはそのしくみや動作を具体的にイメージすることができるでしょうか。
>
> 本書では，Linux OS における，プロセス管理，プロセススケジューラ，メモリ管理，記憶階層，ファイルシステム，記憶階層，そして仮想化機能，コンテナなど，OS とハードウェアに関するしくみがどのように動くのか，実験とその結果を示す豊富なグラフや図解を用いてわかりやすく解説します。
>
> 改訂に際しては全面フルカラー化。グラフや図解がさらにわかりやすくなり，ソースコードは C 言語から，Go 言語と Python にアップデートしています。さらに仮想化，コンテナなどの章が加わりました。今どきの Linux のしくみを本書でしっかり理解しておきましょう。

### 目次

本書の目次は以下の通りのです。

- 序章：はじめに
- 第 1 章：Linux の概要
- 第 2 章：プロセス管理（基礎編）
- 第 3 章：プロセススケジューラ
- 第 4 章：メモリ管理システム
- 第 5 章：プロセス管理（応用編）
- 第 6 章：デバイスアクセス
- 第 7 章：ファイルシステム
- 第 8 章：記憶階層
- 第 9 章：ブロック層
- 第 10 章：仮想化機能
- 第 11 章：コンテナ
- 第 12 章：cgroup
- 終章：本書で学んだことと今後への生かし方

## 各章の振り返り

ここからは各章で印象に残ったことを書いていきます。

### 序章：はじめに

「OS わからない」から「OS 少しわかる」になろうという話がされていました[^00]。

[^00]: 「ﾁｮｯﾄﾜｶﾙ」ではない

### 第 1 章：Linux の概要

OS（Linux）の全体像の話がまとめられていました。

「システムコールとは」、「libc とは」、「静的 / 動的（共有）ライブラリ」とは、のような自分がふわっと理解していた部分の位置づけが理解できました。最近業務で 3rd party 製の dll を使っているプロジェクトがあり、なんだろうと思って調べたことがあったので改めて正しい知識の勉強ができました。

また、`taskset` コマンドを初めて知り、自分で CPU を制御している気持ちになれたのは面白かったです。

### 第 2 章：プロセス管理（基礎編）

`fork()`、`execve()` 関数の挙動確認から始まる章。

数年前にプロセスの概念を知らず、初見で `fork()` 関数の挙動が理解できなくて挫折した記憶が蘇りました。今回は実装して挙動確認まで理解を深めながら進められたと思います。

Linux の実行ファイル形式である ELF（Executable and Linking Format）の中身を見ていく話も良かったです。`readelf` コマンドの実行結果がなんか既視感あるなと思ったら、KOBA789 さんという Rustacean の方の所有権、ライフタイムの解説動画（動画 31 分 15 秒あたり）で出てきたコマンドで「進研ゼミでやったところだ」となり嬉しくなりました。

https://www.youtube.com/live/lG7YbM2AfU8?si=Hdwj60aQWbV2BVjg&t=1875

他には、ゾンビプロセスと `wait()` システムコールの話で、終了したプロセスが使っていたリソースを回収する話やシェルの話が面白かった。特に、最近「シェルってどういうことをしてるんだろう」ともやもやしていましたが、セッション、端末、セッション、フォアグラウンドプロセス、バックグラウンドプロセス、デーモン（常駐プロセス）といった概念が整理されており、自分はターミナル、シェルという言葉を雰囲気で使っていたんだなって気付かされました。

端末の理解を深めるには以下の動画も良かったです。本書と一緒に著者である sat さんの YouTube チャンネルを見ると勉強が捗ります。

https://www.youtube.com/watch?v=ArXSuUCtYLc&ab_channel=satlinuxtube

### 第 3 章：プロセススケジューラ

`sar` コマンドの理解が深まる章。

CPU のタイムスライスの可視化は楽しいので実験してみるのがおすすめです。

コラムのタイムスライスの仕組みが本編で良くねって思うくらいな内容でした。レイテンシーターゲットとプロセス数によりプロセススケジューリングがどうなるかという話で、一定時間に各タスク[^30]がどれくらいの CPU 時間を得られるかの解説が分かりやすかったです。`sar` コマンドを実行したときの `nice` ってなんやねんて思ってた疑問が解消されました。プロセスの CPU への割り当ての優先度を上げ下げできる設定のことでした。

本書の中で紹介されていた以下のスライドも参考にしました。

@[speakerdeck](c79eaa971179471b88a960212a01e87b)

本書では、プロセスのスケジューリング方式について、ラウンドロビンスケジューリングとレイテンシーターゲットによる CFS（Completely Fair Scheduling）というスケジューリング方式を前提にプロセススケジューラの解説をしています（上記スライドでもこの話をしています）。名前にもある通り、タスクに対して一定期間内の CPU 割り当て時間を平等に振り分ける方式で、直感的にも分かりやすいです。

調べてみたところ、ラウンドロビンスケジューリング以外にも以下のようなスケジューリング方式があるみたいです。

> スケジューリングは、複数のスレッドやプロセスを実行するためのタイムシェアリングや優先度付けの方法を指します。以下は、スケジューリングの方法のいくつかの例です。
>
> - ラウンドロビンスケジューリング（Round-Robin Scheduling）：時間分割で実行するスケジューリング方式です。各プロセスは等しい時間（クォンタム）を割り当てられ、その時間が経過すると、プロセスは停止され、他のプロセスが実行されます。ラウンドロビンスケジューリングは、公平であるため、多くの OS で採用されています。
> - 優先度スケジューリング（Priority Scheduling）：各プロセスに優先度を割り当て、優先度の高いプロセスが実行されるようにするスケジューリング方式です。優先度は、静的に割り当てられる場合と、動的に割り当てられる場合があります。
> - 最短ジョブファーストスケジューリング（Shortest Job First Scheduling）：実行時間の短いプロセスを優先的に実行するスケジューリング方式です。長いジョブは待たされる可能性がありますが、短いジョブはすぐに実行されます。
> - マルチキュースケジューリング（Multiqueue Scheduling）：複数の優先度キューを使用して、スケジュールされるプロセスの優先度を調整するスケジューリング方式です。各キューは優先度に応じて異なる割合で時間を割り当てます。

引用元：[並行プログラミングモデル](https://hackmd.io/@LINAp8NKSB60NVYc3zW5EQ/HkX39j_e2#%E9%A3%A2%E9%A4%93%E7%8A%B6%E6%85%8B)

最後に、nice 値とスケジューリングアルゴリズムの関係を補足しておきます。

nice 値はプロセスの属性の一つです。例えば、以下のようなコマンドでプロセス生成時にプロセスの nice 値を指定できます。nice 値の指定できる範囲は -20 ~ 19 で、**値が小さいほどプロセスの優先度が高くなります**。-20 は最高優先度、19 は最低優先度で、デフォルト値は 0 です。

```sh
$ nice -n 10 ./some-batch-job
```

スケジューリングアルゴリズムは、nice 値を重みとしてプロセスの優先度、つまり、プロセスに割り当てる CPU 時間を決定します。nice 値はプロセスの優先度に影響を与えますが、nice 値という重みの解釈はスケジューリングアルゴリズムによって異なります。各プロセスの CPU 時間の最終的な決定はスケジューリングアルゴリズムによって行われます。

基本的には、ユーザからは nice 値を指定できますが、スケジューリングアルゴリズムはカーネルの内部で動作しているためユーザからは直接制御できません。

[^30]: タスクはカーネルのスケジューリングの単位。プロセスまたはスレッドを指す。

### 第 4 章：メモリ管理システム

`free` コマンドの理解が深まる章。

OS のメモリ管理では特に仮想記憶が重要な概念だと思います。本書では「仮想記憶がないとどういう問題が起きるか」というメモリ管理の課題から話が始まり、「仮想記憶（特にページテーブル）の仕組みでそれをどう解決するか」が説明されており、仮想記憶の必要性が理解しやすい構成になっていました。

null / nil pointer エラーで SIGSEGV、Segmentation fault を起こす実験は日頃コードを書いていると起こるのでやりませんでした() アプリケーションの実装をしているとき、Rust を使うとここらへんのエラーは安心ですね。

個人的に面白かったのは、メモリ新規割り当ての `mmap()` システムコールの話で、ページテーブル上のフラグとページフォールトを利用してデマンドページングを実現する流れを見てよくできてるなぁと思いました。

### 第 5 章：プロセス管理（応用編）

コピーオンライト、プロセス間通信、排他制御、マルチプロセスとマルチスレッドの違いあたりの話。

コピーオンライト（CoW、Copy on Write）の仕組みについては、メモリ管理でのデマントページングの仕組みでも似たような種類の話がでてきましたが、「**如何に処理を遅延させて必要になるまでリソース（CPU やメモリ）を確保しないようにするか**」という観点で作られていると思います。コピーオンライトはプロセス

上記のような仕組みは日常のさまざまな場面で現れます。

例えば、ロギングにおいて I/O 処理を遅延させるバッファリング[^50]、フロントエンドのアプリケーションでコンポーネントのロードを必要になるまで遅延させる React の [lazy](https://ja.react.dev/reference/react/lazy) 、言語レベルだと Rust の `Result` 型の[`map_or` / `map_or_else`](https://doc.rust-lang.org/std/result/enum.Result.html#method.map_or) における遅延評価[^49]など、さまざまなレイヤで「処理を遅延させてパフォーマンスを向上させる」という仕組みが使われています。

本書を読んでいるときは、これらの仕組みがコンピュータシステムの様々なレイヤに組み込まれており、それがカーネルのレイヤでも行われているんだな、という理解をしました。本書後半で出てくる、キャッシュメモリからメモリの書き込みを遅延させる方式であるライトバック方式、ページキャッシュからストレージへの書き込みを遅延させるライトバック処理もこの考え方だと思います。このようなハードウェアリソース管理の工夫がないとすぐにリソースが枯渇してしまうのかなと雑に考えていますが、それが実際にどれくらい効いているかの定量的な理解はまだできていません。

プロセス間通信はソケットの話を楽しみに読みましたが、これについては概念に軽く触れただけで終わりました。著者曰く、「本書籍では Linux カーネルに詳しい立場として情報提供しているがネットワークはそのレベルではない（意訳）」とのこと。正直 sat さんの説明力によるカーネルとソケットの解説が読んでみたいです。

排他制御の節では、ファイルロックを例にクリティカルセクション、アトミック処理について書かれています。DB のトランザクションや並行処理で良く出てくる概念なので理解はしやすかったですが、自分で排他制御の仕組みを理解して実装まで落とすのは難しいんだなと感じました。業務や個人開発で Rust の Tokio と Arc、Mutex を使ったコードを書くことがあるため[^52]、ロックによる排他制御のイメージは分かりますが、根本的な理解にはまだまだ遠いなと感じました、、オライリーから以下のようなドンピシャの Rust の本が出ているのを見つけたのでいつか読破したいです。

https://www.oreilly.co.jp/books/9784814400515/

https://blog-dry.com/entry/2024/01/09/082019

コラムのカーネルスレッドとユーザスレッドの話も興味深く読みました。

例えば、論理 CPU [^53]を 1 つ、その上で動かすプロセスを 1 つとした時、プロセスが 2 つのカーネルスレッドを持つ場合、カーネルのスケジューリングの単位であるタスクはカーネルからは 2 つに見え、プロセスが 2 つのユーザスレッドを持つ場合、カーネルからはタスクは 1 つに見えます。本書では、この話をメモリレイアウトとプロセススケジューリングの観点から図解で簡潔に説明してくれており理解が捗りました。

[^49]: `map_or_else` はこの他に副作用を起こす
[^50]: 例えば、Deno の標準ライブラリ std/log の [`FileHandler`](https://github.com/denoland/std/blob/main/log/file_handler.ts#L18) では、デフォルトで 4 KiB のバッファを持ちます。バッファが 4 KiB を超えるか、ログレベルが ERROR を超えるとファイルへの書き込みを行い、バッファをリセットする、という実装になっています。[`FileHandler.handle()`、`FileHandler.log()` メソッドの実装](https://github.com/denoland/std/blob/main/log/file_handler.ts#L87_L107)はロギングにおけるバッファリングの仕組みを実装レベルで理解する上で分かりやすい題材だと思います。レイヤは異なりますが、ロギングのエージェントである [Fluentd](https://docs.fluentd.org/configuration/buffer-section) / [Fluent Bit](https://docs.fluentbit.io/manual/administration/buffering-and-storage) や、[Amazon CloudWatch Agent](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-Configuration-File-Details.html#CloudWatch-Agent-Configuration-File-Logssection:~:text=force_flush_interval) にももちろんバッファリングの仕組みがあります。
[^51]: 自分の読んでいる書籍が入門よりなものが多いからだとは思うのですが、ソケットの解説でネットワーク割り込みまで踏み込んで全体像を解説してくれるものがなかなか見つからず、、おすすめあればぜひ教えて下さい。
[^52]: 普段の業務で Tokio のスレッド（非同期タスク）間のデータのやり取りを実装することがありますがチャネルを使うことの方が多いです。これはもちろん要件によるところだとは思います。
[^53]: 論理 CPU（LCPU、Logical CPU）はカーネルが実行可能な CPU として認識するもの。物理 CPU or コア or スレッド（このスレッドはプロセスの「スレッド」とは無関係）。ちなみに、Rust では [num_cpus](https://docs.rs/num_cpus/latest/num_cpus/) というクレートを使うと Physical / Logical CPU どちらの数も取得できます。

### 第 6 章：デバイスアクセス

プロセスによるデバイス操作、つまりプロセスのデバイス I/O の仕組みを解説している章。

主な登場人物はプロセス、デバイスファイル、デバイスドライバです。デバイスファイルは Linux の `/dev` ディレクトリ配下に格納されているファイルで、プロセスが安全にデバイスへアクセスするためのインタフェースです。プロセスがデバイスを扱いやすいように OS が抽象化してくれています。

1 つ注意が必要で、我々がアプリケーションでストレージデバイスへアクセスする実装を行う場合には、基本的には、

- アプリケーション → デバイスファイル → デバイスドライバ → デバイス

ではなく、ファイルシステムを介して、

- アプリケーション → ファイルシステム上のファイル → デバイスドライバ → デバイス

の順にアクセスします。これについては次章で説明されています。

個人的に面白かったのは、メモリマップト I/O と「デバイスドライバがストレージデバイスに依頼した処理の完了をどう受け取るか」の仕組みの解説です。

メモリマップト I/O は、デバイスのレジスタ[^60]への I/O を「CPU のメモリへの I/O」で実現する仕組みです。CPU がメモリへの I/O と同じようにデバイスの操作をすることができることで、「アーキテクチャがシンプルになり製造コストが低くなる」や「メモリと I/O デバイスが同じアドレス空間に存在するため、アドレス管理が楽になる」などの嬉しさがあるみたいです[^61]。

デバイスドライバがストレージデバイスに依頼した処理の完了をどう受け取るかの仕組みについては、「ポーリング」と「割り込み」の解説をしています。ここの図解はとても分かりやすかったです。ここでは、アプリケーションレイヤで「状態の更新をどう検知するか」を実装するときに、ポーリングかイベント駆動（WebSocket やメッセージングなど）で実装するのに似たような仕組みがカーネルレイヤにもあるという理解をしました。

[^60]: CPU のレジスタと同じ名前だけど無関係。デバイスのレジスタは、ストレージデバイスに限らず、さまざまな種類のハードウェアデバイス（ネットワークカード、グラフィックスカード、サウンドカードなど）に存在する。
[^61]: ここの利点は正直まだ理解できていません。これは比較対象の概念であるポートマップド I/O を学べば理解できるんでしょうか。

### 第 7 章：ファイルシステム

### 第 8 章：記憶階層

### 第 9 章：ブロック層

### 第 10 章：仮想化機能

### 第 11 章：コンテナ

### 第 12 章：cgroup

### 終章：本書で学んだことと今後への生かし方

## 知識の整理

本書の内容 + 自分で調べた内容を元に、ここまでで学んだ知識の整理をしてみます。

日常でよく遭遇する「ファイルへの書き込み」、「ターミナルでコマンドを実行する」を例にそれぞれの仕組みを説明を試みます。説明の内容によって粒度、抽象度は異なります。

ここからの説明では以下の環境を前提としています。

- OS: Ubuntu 24.04 LTS
- CPU アーキテクチャ: ARM64 (ARMv8 / aarch64)
- Rust 1.81.0

### 「ファイルへの書き込みをする」ときに何が起きているか

ここでは、メモリマップド I/O を利用して特定のデバイスへの書き込みを行う手順を、ファイル書き込みを行うアプリケーションを例に説明してみます。

本書では、ページテーブルについては触れていたが、それを管理する[メモリ管理ユニット](https://milestone-of-se.nesuke.com/sv-basic/architecture/user-space-kernel-space/)（MMU、Memory Management Unit）までは触れられていませんでしたが、この手順の説明では MMU も含めています。

1.  アプリケーションがファイルへの書き込み処理を呼び出す（下記コード `file.write_all()` メソッド）。内部的に Linux の `write()` システムコールが発行される。
2.  システムコールの発行によって、CPU がユーザモードからカーネルモードに切り替わる
3.  カーネル内でファイルシステム → 該当するデバイスドライバの順に呼び出される。デバイスドライバは、デバイスのレジスタに書き込むべき値と、そのレジスタのメモリマップトアドレスを特定する。
4.  デバイスドライバは、CPU に対して、特定のメモリアドレス（実際はデバイスのレジスタに対応）への書き込み命令を発行する
5.  CPU がこの書き込み命令を実行しようとしようとする
6.  MMU が、CPU が使用する論理アドレスを物理アドレスに変換する
7.  MMU が、手順 7 の物理アドレスがデバイスのレジスタに対応していることを検出し、メモリへのアクセスではなくデバイスへのアクセスとして処理する
8.  CPU が変換された物理アドレス（デバイスのレジスタに対応）に対して書き込み操作を実行する
9.  この書き込み操作は、実際にはデバイスのレジスタに送られ、デバイスによって処理される
10. デバイスは、レジスタに書き込まれた値に基づいて書き込み処理を行う
11. 操作が完了すると、デバイスは通常、割り込みを生成して CPU に通知する。割り込みを発生させるコントローラのことを「割り込みコントローラ」という。
12. CPU は割り込みを受け取り、デバイスドライバの対応する割り込みハンドラを呼び出す
13. デバイスドライバは、操作の結果を確認し、アプリケーションに結果を返す
14. CPU がユーザモードに戻り、アプリケーションに結果を返す
15. アプリケーションは、ファイルへの書き込み処理が完了したことを確認し、後続の処理を行う

### システムコールの深堀り

ファイルへの書き込みを行うアプリケーションを例に、Linux の `write()` システムコールが発行される過程を深堀りしてみます。

アプリケーションのコードは以下のとおりです。ファイルへの書き込みを行うだけのシンプルなコードです。

```rust
use std::fs::File;
use std::io::Write;
use std::path::Path;

fn main() -> std::io::Result<()> {
    // 書き込むデータ
    let data = "Hello, this is a test of writing to storage!";

    // ファイルを開く
    let path = Path::new("test_file.txt");
    let mut file = File::create(&path)?;

    // ファイルへの書き込み
    file.write_all(data.as_bytes())?;
    println!("Data written successfully to {:?}", path);

    Ok(())
}
```

`file.write_all()` メソッドの定義をたどると、`unsafe` ブロックの中で libc クレートの `libc::write()` 関数を呼び出している部分にたどり着きます。

```rust
// /home/nukopy/.rustup/toolchains/stable-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/sys/pal/unix/fd.rs
impl FileDesc {
    ...
    pub fn write(&self, buf: &[u8]) -> io::Result<usize> {
        let ret = cvt(unsafe {
            libc::write(
                self.as_raw_fd(),
                buf.as_ptr() as *const libc::c_void,
                cmp::min(buf.len(), READ_LIMIT),
            )
        })?;
        Ok(ret as usize)
    }
    ...
}
```

libc クレートは、C 言語で実装されている glibc の関数を Rust から呼び出すためのラッパー関数を提供しています。`libc::write()` 関数は、Linux の `write()` システムコールのラッパー関数である glibc の `write() 関数のラッパー関数です。

少しややこしい日本語になってしまいましたが、整理すると以下のような依存関係になります。

- アプリケーションのコード（Rust）
  - `std::fs::File` の `write_all()` メソッド
    - ...（省略）
    - `libc::write()` 関数（glibc の `write()` 関数のラッパー関数）
      - glibc の `write()` 関数（`write()` システムコールのラッパー関数）
        - Linux の `write()` システムコール

libc クレートの `libc::write()` 関数の宣言は、[rust-lang/libc](https://github.com/rust-lang/libc) リポジトリの [`libc/src/unix/mod.rs`](https://github.com/rust-lang/libc/blob/2c0250f5adab47f99d94ef80e82a87f7dfe5e8f5/src/unix/mod.rs#L950) 内で行われています。

以下のコードでは、`extern "C"` で C 言語の `write()` 関数を呼び出すためのインタフェースを定義しています。これは FFI（Foreign Function Interface、外部関数インタフェース）と呼ばれる機能で、Rust 以外の言語で書かれた関数を Rust から呼び出すための仕組みです。

```rust
// https://github.com/rust-lang/libc/blob/2c0250f5adab47f99d94ef80e82a87f7dfe5e8f5/src/unix/mod.rs#L950
extern "C" {
    ...
    pub fn write(fd: c_int, buf: *const c_void, count: size_t) -> ssize_t;
    ...
}
```

Rust から呼び出される C 言語の `write()` 関数は glibc で実装されています。

- [リポジトリ](https://sourceware.org/git/glibc.git)
- [ミラーリポジトリ](https://github.com/bminor/glibc)

実装は [`glibc/sysdeps/unix/sysv/linux/write.c`](https://github.com/bminor/glibc/blob/e64a1e81aadf6c401174ac9471ced0f0125c2912/sysdeps/unix/sysv/linux/write.c) にあります。

```c
/* Write NBYTES of BUF to FD.  Return the number written, or -1.  */
ssize_t
__libc_write (int fd, const void *buf, size_t nbytes)
{
  return SYSCALL_CANCEL (write, fd, buf, nbytes);
}
```

`__libc_write()` 関数は、`SYSCALL_CANCEL()` マクロを呼び出しています。`SYSCALL_CANCEL()` マクロの中身を見てみます。`SYSCALL_CANCELL` マクロは `glibc/sysdeps/unix/sysdep.h` に定義されています。

Rust で glibc が使用される場合、glibc は動的リンカによってロードされるため、`IS_IN (rtld)` は false になり、`SYS_CALL_CANCEL()` マクロの中身は `__INTERNAL_SYSCALL_CANCEL_CALL()` に展開されます。`__INTERNAL_SYSCALL_CANCEL_CALL()` マクロの中身は、`__SYSCALL_CANCEL_CALL()` マクロに展開されます。

https://github.com/bminor/glibc/blob/e64a1e81aadf6c401174ac9471ced0f0125c2912/sysdeps/unix/sysdep.h#L243-L253

```c
#if IS_IN (rtld)
/* The loader does not need to handle thread cancellation, use direct
   syscall instead.  */
# define INTERNAL_SYSCALL_CANCEL(...) INTERNAL_SYSCALL_CALL(__VA_ARGS__)
# define SYSCALL_CANCEL(...)          INLINE_SYSCALL_CALL (__VA_ARGS__)
#else
# define INTERNAL_SYSCALL_CANCEL(...) \
  __INTERNAL_SYSCALL_CANCEL_CALL (__VA_ARGS__)
# define SYSCALL_CANCEL(...) \
  __SYSCALL_CANCEL_CALL (__VA_ARGS__)
#endif
```

さらに `__SYSCALL_CANCEL_CALL()` マクロの中身を見てみます。

https://github.com/bminor/glibc/blob/e64a1e81aadf6c401174ac9471ced0f0125c2912/sysdeps/unix/sysdep.h#L205-L206

```c
#define __SYSCALL_CANCEL_CALL(...) \
  __SYSCALL_CANCEL_DISP (__SYSCALL_CANCEL, __VA_ARGS__)
```

### 「ターミナルでコマンドを実行する」ときに何が起きているか

デバイスファイルについて学んだので、第 2 章のプロセス管理、シェル、端末の話と合わせて知識を整理してみます。

ここでは、「ターミナルエミュレータ[^100]を起動してフォアグラウンドでコマンドを実行する」際に何が起きているかの説明を試みます。Ubuntu 24.04 LTS で GNOME Terminal（Ubuntu のデフォルトのターミナル）を使っていることを前提に説明します。

1. デスクトップアプリであるターミナルエミュレータを起動する
2. ターミナルエミュレータが擬似端末（pty、pseudoterminal）を開く
3. ターミナルエミュレータが `fork()` を実行し、子プロセスを生成する
4. 子プロセス上で、`execve()` を実行しシェル（`/bin/bash` とする）を起動する。
   - シェルのファイルディスクリプタテーブルは、ターミナルエミュレータのファイルディスクリプタテーブルを引き継ぐ。このため、シェルはターミナルエミュレータへの入力を pty を介して受け取ることができ、シェルの出力は pty を介してターミナルエミュレータに表示されるようになる。
   - ユーザの入力（標準入力）：
     - ターミナルエミュレータへの入力の表示の流れ：ユーザの入力 → ターミナルエミュレータ → pty → ターミナルエミュレータ
     - シェルへの入力の流れ：ユーザの入力 → ターミナルエミュレータ → pty（バッファリング）→ ユーザの Enter 入力 → ターミナルエミュレータ → pty（バッファの内容をシェルへ送信） → シェル
   - シェルの標準出力：シェル → pty → ターミナルエミュレータ
   - シェルの標準エラー出力：シェル → pty → ターミナルエミュレータ
5. シェルが設定ファイルを読み込む（`~/.bashrc` など）
6. シェルが環境変数 `PS1` に設定されたプロンプト文字列を標準出力へ出力し、ターミナルエミュレータにプロンプトが表示される
7. ユーザがキーボードからキー入力を行うと、ターミナルエミュレータが標準入力を受け取り、文字列をウィンドウに表示する。
   - 実際には、キーボード → 割り込みハンドラ → キーボードドライバ（デバイスドライバ） → カーネルの入力サブシステム[^99]→ X Window System → ターミナルエミュレータ → pty
8. ユーザがキーボードから Enter（`\n`）キーを押すと、ターミナルエミュレータ、pty を介して `\n` を含む入力内容がシェルに送信される
9. シェルが入力内容を受け取り、コマンドを解析する
   - 内部コマンド（シェルのビルトインコマンド）の場合
     - シェル自身がコマンドを実行する
   - 外部コマンドの場合
     1. シェルが `fork()` し、子プロセスを生成する
     2. 子プロセス上で、`execve()` を実行し、コマンドを実行する
     3. コマンドの標準出力、標準エラー出力は pty を介してターミナルエミュレータに表示される
10. コマンドの実行が終了すると、シェルが子プロセスの終了状態を取得する。ここでは、wait 系システムコール（`wait()` や `waitpid()`）が発行される。
    - 例えば、シェルは子プロセスの終了状態に含まれる終了ステータスコード[^101]を取得し `$?` に格納し、ユーザが参照できるようにする
11. シェルが新たなプロンプトを表示し、ユーザの入力を待つ
12. 7 ~ 11 を繰り返す

[^99]: デバイスドライバとアプリケーションの中間層。入力イベントをアプリケーションへ配信する
[^100]: Linux の GNOME Terminal や macOS の純正ターミナルなど
[^101]: 終了ステータス、ステータスコード、exit コードとも呼ばれる。`exit()` 関数の引数として渡される値を 256 で割った余りが終了ステータスコードとして扱われる。そのため、一般的に 0 ~ 255 の範囲で扱われる。0 は正常終了、それ以外は異常終了を示す。

## 感想

全体的に OS の概念の説明がわかりやすかった。個人のレベルやタイミングもあるんだろうけど、今自分がまさに知りたいなーと思っていた、プロセススケジューラ含むプロセス管理、メモリ管理、デバイス管理、コンテナあたりの基礎知識（ほぼ目次じゃん）が体系的にまとまっていて飽きずに読めた。言葉の説明が丁寧で、入門書でよくある例えによって概念の説明を濁すような表現がほぼなかったと思う。また、初出の概念の説明とその詳細の説明の省き方のバランスがよく、本題から逸れすぎたり置いてけぼりになることはあまりなかった。

そして、本書の特徴の「手を動かす」部分がとても面白かった。実験環境は物理マシンがなかったので VirtualBox を使用して Ubuntu 20.04 で動かしていた。

すんなり読めたかのように書いたが、ネタバラシをするとここ数年間で 3 回ほど本書に挑戦しては挫折していた（数章読んで放置を繰り返した...）。今回はようやく通読することができた。これまでと違い内容がすっと入ってくる項目が増え、自身の成長を少し感じることができて嬉しい。

これは業務で Deno を使ったプロセスマネージャの開発をしたり、Rust / Tokio を使ってマルチスレッドでデータをさばく処理を書いたりした時に、OS の基本的なプロセス管理、I/O 周り、カーネルスレッド / ユーザスレッドを使ったマルチスレッドプログラミングあたりについて地道に調べたのが効いたかなと思う。断片的に学んできた OS の知識の体系化が進んだ。

総じて OS への入門ができたので、引き続き手を動かしながら低レイヤの勉強を進めていこうと思う。次は「詳解 Rust プログラミング」を読む予定。次に読む本を探していたところ以下の記事に出会い、ちょうど自分がやりたい領域のことが書いていそうだった。

[https://blog-dry.com/entry/2021/11/19/000400:embed:cite]

## 補足：通読にかかった時間

- 期間：6 日間
- 時間：14 時間 30 分
